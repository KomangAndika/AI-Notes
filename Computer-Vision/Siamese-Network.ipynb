{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network\n",
    "Neural network is almost good at every problem but they tend to rely on the need of more data or batter quality data. Problem like face recognition and signature verification, we can't always rely on more data. To solve this problem a new type of neural network is used called Siamese Networks. It only use few numbers of images to get better predictions, it has the ability to learn from very little data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Siamese Network\n",
    "Is a class of neural network architecture that contain two or more identical subnetworks. \"identical\" mean they have same configuration with the same parameters and weight. Parameter updating is mirrored across sub-networks. It is used to find the similarityof the inputs by comapring its features vectors. <br><br>\n",
    "Traditionally normal NN learns to predict multiple classes, this can be problematic when adding or removing new classes to the adta, in this case we have to update the NN and retrain the whole dataset. Also Deep neural network need large volume of data to train on. SNN (Siamese Neural Network) on the other hand only learn similarity function. Thus we can train it to see of two image are the same. This enables us to classify new classes of data without training the network again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of SNN\n",
    "**Pros:**\n",
    "1. More robust to class imbalance, with the aid of one-shot learning, given a few images per class is sufficient for SNN to recognize images in the futures.\n",
    "2. Nice to an ensemble with the best classifier, given the learning mechanism it is somewhat different from classification, simple averaging of it with a classifier can do much better than average 2 correlated supervised model (e.g. GBM & RF classifier).\n",
    "3. Learning from semantic similarity, siamese focuses on learning embedding (in the deeper layer) that place the same classes/concepts close together. Hence can learn semantic similarity.\n",
    "<br><br>\n",
    "\n",
    "**Cons:**\n",
    "1. Needs more training time than normal networks, since siamese networks involves quadratic pairs to learn from (to see all information available) it is slower than normal classification type of learning(pointwise learning)\n",
    "2. Doesn't output probabilities, since training involves pairwise learning, it won't output the probabilities of the predicition but the distance from each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Model using Traditional Deep Learning Neural Network Architecture\n",
    "You first need to obtained labeled dataset containing images of dogs and cats. After training the neural network, and upon gicing any input image the network can only output labels as dog or cat. This is standard computer vision problem known as Image Classification.<br>\n",
    "In classification, the image is given into the NN and the output layer give the list of probability distribution over all classes (using softmax or other activation function as per the classification problem being solved).<br>\n",
    "For example i want to classify if this image is cat ot not then for every inpu image we generate two probabilities indicating the probability of the image belonging to each of the 2 classes, but when training we require a lot of images of each class and the model can only predict from the trained labels. <br>\n",
    "<span style=\"background-color: #FFFFED\">One problem where we might come across is when we want to create employee attendance systems, this the cost of data collection and re-training is high each time a new class is added or a new employee joins</span> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Similarity Learning?\n",
    "Technique of supervised machine learning in which the goal is make the model learn, which is a similarity function that measures how similar two objects are and returns a similarity value.<br>\n",
    "- High score is returned when objects are similar.\n",
    "- Low score is returned when objects are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Use Case of Siamese Network\n",
    "Most popular use cases of similarity learning are employee attendance and signature varification system. In siamese network, we require only one training example for each class. Due to this name One Shot.\n",
    "### Employee attendace system\n",
    "- Let's say I want to create an attendance system for a small organization with 20 employees \n",
    "There will be some challenges in this attendance system:\n",
    "1. The need of different images of each employee.\n",
    "2. New employee or employee leaving -> re-train again. Basically not scalabel. (Which makes siamese network model great solution)\n",
    "Insted of classifying a test image to one of the 20 people, the siamese network takes a reference image of the person as input and generates similarity score denoting the probability that the two input images are of the same person. <br> <br>\n",
    "The similarity score lies from 0-1 (where 0 means no similarity and 1 means full similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of SNN\n",
    "![SNN Architecture](Pict/Siamese_network.png \"SNN Architecture\") <br> <br>\n",
    "Containing two or more identical sub-networks, they have the same configuration with the same parameters and wights. Mostly, we only train one if N (the number of subnetworks chosen for solving the problem) the subnetworks and use the same configuration (params and wights) for other sub-networks. SNN used to find the similarity of the inputs by comparing their feature vectors. <br><br>\n",
    "\n",
    "How does it works? <br>\n",
    "1. The first subnetworks takes an image (A) as input and passes through convolutional layers and fully connected layers, we get a vector representation of the image.\n",
    "2. Again the second image (B) through a network that is exactly the same with the same weights and parameters.\n",
    "3. Now both the encoding can be compared to know how similar they are, if the images are similar then the encoding wil also be quite similar.\n",
    "4. We will measure the distance between these two vectors and if the distance between these is small then the vectors are similar or the same classes and if the distance is larger then the vectors are different from one another, based on the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "Since training SNN involves pairwise learning usual, cross enthropy loss cannot be used in this case, mainly there are two loss functions used in training Siamese networks:\n",
    "1. Triplet Loss\n",
    "Where baseline(anchor) is comapred to a positive (thruthy) input and a negative (falsy) input. The distance from baseline input to the positive is minimized and the distance from baseline input to the negative is maximized. During the training process, an image triplet (anchor image, negative image, positive image)(anchor image, negative image, positive image) is fed into the model as a single sample. The idea behind this is that distance between the anchor and positive images should be smaller than that between the anchor and negative images.\n",
    "2. Contrastive Loss\n",
    "It is a distance-based loss as opposed to more conventional error-prediction losses. This loss is used to learn embeddings in which two similar points have a low Euclidean distance and two dissimilar points have a large Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training + Testing\n",
    "- Initialize the siamese network, loss function, optimizer(Adam, Adagrad, SGD etc).\n",
    "- Pass the images one by one out of the image pairs through the siamese network, as here training involves pairwise learning.\n",
    "- Calculate the loss using the outputs from the first and second images using the loss.\n",
    "- Back propogate through the model to calculate the gradients of our model.\n",
    "- Update the weights using an optimizer to minimize the loss after a certain number of epochs.\n",
    "- After reaching max epochs we have set for the model and also get the least loss possible.\n",
    "- Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Using Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path\n",
    "BASE_PATH = os.path.join('/Users/komangandikawirasantosa', 'AI-Notes', 'Computer-Vision', 'data')\n",
    "\n",
    "# Setup paths\n",
    "POS_PATH = os.path.join(BASE_PATH, 'positive')\n",
    "NEG_PATH = os.path.join(BASE_PATH, 'negative')\n",
    "ANC_PATH = os.path.join(BASE_PATH, 'anchor')\n",
    "\n",
    "# Make the directories\n",
    "os.makedirs(POS_PATH, exist_ok=True)\n",
    "os.makedirs(NEG_PATH, exist_ok=True)\n",
    "os.makedirs(ANC_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "- [A Comprehensive Guide to Siamese Neural Networks by Rinki Nag](https://medium.com/@rinkinag24/a-comprehensive-guide-to-siamese-neural-networks-3358658c0513)\n",
    "- [A friendly introduction to Siamese Networks by Sean Benhur](https://towardsdatascience.com/a-friendly-introduction-to-siamese-networks-85ab17522942)\n",
    "- [Build a Python Facial Recognition App with Tensorflow and Kivy by Nicholas Renotte on YouTube](https://www.youtube.com/watch?v=LKispFFQ5GU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanks 4 readin dis <3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
